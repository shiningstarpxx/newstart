



> 加入linked in的时候，正好赶上重构单体化，中心化的数据库，要变成分布式的系统。最终构建了成了图数据库，一个分布式的检索后端服务，和一个key-value的存储
>
> 构建这些的核心思想：日志。更具体的说是，write ahead log （WAL）或者是traction log。日志有着悠久的历史，是许多分布式系统和实时应用结构的核心。
>
> 如果不懂log，无法理解databases, NoSQL stores, key value stores, replication, paxos, hadoop, version control, or almost any software system 。 本文会介绍log，**what is log and how to use logs for data integration, real time processing, and system building.**
>
> *** Part One: What is Log ***
>
> A log is perhaps the simplest possible storage abstraction. It is an append-only, totally-ordered sequence of records ordered by time. It looks like this:
>
> ![](https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/log.png)
>
> Records are appended to the end of the log, and reads proceed left-to-right. Each entry is assigned a unique sequential log entry number.
>
> The ordering of records defines a notion of "time" since entries to the left are defined to be older then entries to the right（事实上，上面这句话不一定对）. The log entry number can be thought of as the "timestamp" of the entry. Describing this ordering as a notion of time seems a bit odd at first, but it has the convenient property that it is decoupled from any particular physical clock. This property will turn out to be essential as we get to distributed systems. (序列等价于timestamp)
>
> The contents and format of the records aren't important for the purposes of this discussion. Also, we can't just keep adding records to the log as we'll eventually run out of space. I'll come back to this in a bit. (日志的内容和格式不在讨论范围内)
>
> So, a log is not all that different from a file or a table. A file is an array of bytes, a table is an array of records, and a log is really just a kind of table or file where the records are sorted by time. （文件是bytes的数组，table是records的数组，log跟table和文件类似，只是记录按时间排序了）
>
> At this point you might be wondering why it is worth talking about something so simple? How is a append-only sequence of records in any way related to data systems? The answer is that logs have a specific purpose: they record what happened and when. For distributed data systems this is, in many ways, the very heart of the problem （日志记录了何时发生，且发生了什么，对分布式系统来说，这就是核心 -- 原则上没有GST，这个也不是很准确）
>
> -But before we get too far let me clarify something that is a bit confusing. Every programmer is familiar with another definition of logging—the unstructured error messages or trace info an application might write out to a local file using syslog or log4j. For clarity I will call this "application logging". The application log is a degenerative form of the log concept I am describing. The biggest difference is that text logs are meant to be primarily for humans to read and the "journal" or "data logs" I'm describing are built for programmatic access. （应用日志用于给人读，而“journal”或者“data logs”用来构建系统）
>
> (Actually, if you think about it, the idea of humans reading through logs on individual machines is something of an anachronism. This approach quickly becomes an unmanageable strategy when many services and servers are involved and the purpose of logs quickly becomes as an input to queries and graphs to understand behavior across many machines—something for which english text in files is not nearly as appropriate as the kind structured log described here.) （单机或许可读，集群将无法处理，需要查询或者图来理解--也就是说文本比不上结构化）
>
> **Log In Database**
>
> I don't know where the log concept originated—probably it is one of those things like binary search that is too simple for the inventor to realize it was an invention. It is present as early as IBM's [System R](http://www.cs.berkeley.edu/~brewer/cs262/SystemR.pdf). The usage in databases has to do with keeping in sync the variety of data structures and indexes in the presence of crashes. To make this atomic and durable, a database uses a log to write out information about the records they will be modifying, before applying the changes to all the various data structures it maintains. The log is the record of what happened, and each table or index is a projection of this history into some useful data structure or index. Since the log is immediately persisted it is used as the authoritative source in restoring all other persistent structures in the event of a crash. (日志在IBM的System R中出现，主要是在crash时，来保持索引和各种数据结构的同步。为了保证原子化和持久化， 数据库先写日志，然后再做更改，log描述了发生了什么。因为日志会立刻持久化，在crash后，它就会作为最有权威的数据源)
>
> Over-time the usage of the log grew from an implementation detail of ACID to a method for replicating data between databases. It turns out that the sequence of changes that happened on the database is exactly what is needed to keep a remote replica database in sync. Oracle, MySQL, and PostgreSQL include log shipping protocols to transmit portions of log to replica databases which act as slaves. Oracle has productized the log as a general data subscription mechanism for non-oracle data subscribers with their [XStreams](http://docs.oracle.com/cd/E11882_01/server.112/e16545/xstrm_intro.htm) and [GoldenGate](http://www.oracle.com/technetwork/middleware/goldengate/overview/index.html) and similar facilities in MySQL and PostgreSQL are key components of many data architectures. （日志一开始是ACID的实现细节，后来发展成为了replication的细节。Oracle， MySQl， PGSQL都用来实现replica，同时还提供了数据订阅data subscription为异构数据源）
>
> Because of this origin, the concept of a machine readable log has largely been confined to database internals. The use of logs as a mechanism for data subscription seems to have arisen almost by chance. But this very abstraction is ideal for supporting all kinds of messaging, data flow, and real-time data processing. （日志的这种抽象，很适合支持其他消息类型，类似数据流，实时数据处理）
>
> **Log in Distributed System**
>
> The two problems a log solves—ordering changes and distributing data—are even more important in distributed data systems. Agreeing upon an ordering for updates (or agreeing to disagree and coping with the side-effects) are among the core design problems for these systems. (日志解决的两个问题：改变顺序和分布式数据 -- 对于分布式数据系统来说更为重要)
>
> The log-centric approach to distributed systems arises from a simple observation that I will call the State Machine Replication Principle: (状态机replication原则)
>
> > If two identical, deterministic processes begin in the same state and get the same inputs in the same order, they will produce the same output and end in the same state. （相同状态，相同输入要得到相同的输出）
>
> [Deterministic](http://en.wikipedia.org/wiki/Deterministic_algorithm) means that the processing isn't timing dependent and doesn't let any other "out of band" input influence its results. For example a program whose output is influenced by the particular order of execution of threads or by a call to `gettimeofday` or some other non-repeatable thing is generally best considered as non-deterministic. (确定性，随着时间变化结果不会变化）
>
> The *state* of the process is whatever data remains on the machine, either in memory or on disk, at the end of the processing.
>
> The bit about getting the same input in the same order should ring a bell—that is where the log comes in. This is a very intuitive notion: if you feed two deterministic pieces of code the same input log, they will produce the same output.  （确定性只能靠log来实现）
>
> The application to distributed computing is pretty obvious. You can reduce the problem of making multiple machines all do the same thing to the problem of implementing a distributed consistent log to feed these processes input. The purpose of the log here is to squeeze all the non-determinism out of the input stream to ensure that each replica processing this input stays in sync. (问题的降级：把多个机器做一样事情的问题变成实现一个分布式的一致性日志送给这些机器处理)
>
> When you understand it, there is nothing complicated or deep about this principle: it more or less amounts to saying "deterministic processing is deterministic". Nonetheless, I think it is one of the more general tools for distributed systems design. （原则：确定的处理是确定的 -- 分布式系统设计的更通用工具）
>
> One of the beautiful things about this approach is that the time stamps that index the log now act as the clock for the state of the replicas—you can describe each replica by a single number, the timestamp for the maximum log entry it has processed. This timestamp combined with the log uniquely captures the entire state of the replica. （日志的index等同于timestamp，表明了我们处理的状态）
>
> There are a multitude of ways of applying this principle in systems depending on what is put in the log. For example, we can log the incoming requests to a service, or the state changes the service undergoes in response to request, or the transformation commands it executes. Theoretically, we could even log a series of machine instructions for each replica to execute or the method name and arguments to invoke on each replica. As long as two processes process these inputs in the same way, the processes will remaining consistent across replicas. （日志可以详细的记录每个操作，以此实现分片操作后的一致性）
>
> Different groups of people seem to describe the uses of logs differently. Database people generally differentiate between *physical* and *logical* logging. Physical logging means logging the contents of each row that is changed. Logical logging means logging not the changed rows but the SQL commands that lead to the row changes (the insert, update, and delete statements). （DB physical log是row 的变化，logical log是sql）
>
> The distributed systems literature commonly distinguishes two broad approaches to processing and replication. The "state machine model" usually refers to an active-active model where we keep a log of the incoming requests and each replica processes each request. A slight modification of this, called the "primary-backup model", is to elect one replica as the leader and allow this leader to process requests in the order they arrive and log out the changes to its state from processing the requests. The other replicas apply in order the state changes the leader makes so that they will be in sync and ready to take over as leader should the leader fail. （分布式系统有两种方式处理和分片：state machine模式是记录进入的请求，每个分片执行这个请求。primary-backup 模式是选举一个leader处理请求，记录的是它状态的改变，其他的分片则按顺序执行这些改变，以此保持和主的一致）
>
> ![](https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/active_and_passive_arch.png)
>
> To understand the difference between these two approaches, let's look at a toy problem. Consider a replicated "arithmetic service" which maintains a single number as its state (initialized to zero) and applies additions and multiplications to this value. The active-active approach might log out the transformations to apply, say "+1", "*2", etc. Each replica would apply these transformations and hence go through the same set of values. The "active-passive" approach would have a single master execute the transformations and log out the *result*, say "1", "3", "6", etc. This example also makes it clear why ordering is key for ensuring consistency between replicas: reordering an addition and multiplication will yield a different result.(举个例子让我们明白上面的bb)
>
> The distributed log can be seen as the data structure which models the problem of consensus. A log, after all, represents a series of decisions on the "next" value to append. You have to squint a little to see a log in the Paxos family of algorithms, though log-building is their most common practical application. With Paxos, this is usually done using an extension of the protocol called "multi-paxos", which models the log as a series of consensus problems, one for each slot in the log. The log is much more prominent in other protocols such as [ZAB](http://www.stanford.edu/class/cs347/reading/zab.pdf), [RAFT](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf), and [Viewstamped Replication](http://pmg.csail.mit.edu/papers/vr-revisited.pdf), which directly model the problem of maintaining a distributed, consistent log.（日志，分布式协议的基石） 
>
> My suspicion is that our view of this is a little bit biased by the path of history, perhaps due to the few decades in which the theory of distributed computing outpaced its practical application. In reality, the consensus problem is a bit too simple. Computer systems rarely need to decide a single value, they almost always handle a sequence of requests. So a log, rather than a simple single-value register, is the more natural abstraction.(日志发展太快，理论没跟上)
>
> Furthermore, the focus on the algorithms obscures the underlying log abstraction systems need. I suspect we will end up focusing more on the log as a commoditized building block irrespective of its implementation in the same way we often talk about a hash table without bothering to get in the details of whether we mean the murmur hash with linear probing or some other variant. The log will become something of a commoditized interface, with many algorithms and implementations competing to provide the best guarantees and optimal performance.
>
> **Chanelog 101: Tables and Events are Dual**
>
> Let's come back to databases for a bit. There is a facinating duality between a log of changes and a table. The log is similar to the list of all credits and debits and bank processes; a table is all the current account balances. If you have a log of changes, you can apply these changes in order to create the table capturing the current state. This table will record the latest state for each key (as of a particular log time). There is a sense in which the log is the more fundamental data structure: in addition to creating the original table you can also transform it to create all kinds of derived tables. (And yes, table can mean keyed data store for the non-relational folks.) (DTS的理论基础)
>
> ![](https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/yin-yang.jpg)
>
> This process works in reverse too: if you have a table taking updates, you can record these changes and publish a "changelog" of all the updates to the state of the table. This changelog is exactly what you need to support near-real-time replicas. So in this sense you can see tables and events as dual: tables support data at rest and logs capture change. The magic of the log is that if it is a *complete* log of changes, it holds not only the contents of the final version of the table, but also allows recreating all other versions that might have existed. It is, effectively, a sort of backup of *every* previous state of the table. (还是DTS那套)
>
> This might remind you of source code version control. There is a close relationship between source control and databases. Version control solves a very similar problem to what distributed data systems have to solve—managing distributed, concurrent changes in state. A version control system usually models the sequence of patches, which is in effect a log. You interact directly with a checked out "snapshot" of the current code which is analogous to the table. You will note that in version control systems, as in other distributed stateful systems, replication happens via the log: when you update, you pull down just the patches and apply them to your current snapshot.
>
> Some people have seen some of these ideas recently from [Datomic](http://www.datomic.com/), a company selling a log-centric database. This [presentation](https://www.youtube.com/watch?v=Cym4TZwTCNU) gives a great overview of how they have applied the idea in their system. These ideas are not unique to this system, of course, as they have been a part of the distributed systems and database literature for well over a decade.
>
> This may all seem a little theoretical. Do not despair! We'll get to practical stuff pretty quickly.
>
> **What's next**
>
> In the remainder of this article I will try to give a flavor of what a log is good for that goes beyond the internals of distributed computing or abstract distributed computing models. This includes:
>
> 1. *Data Integration*—Making all of an organization's data easily available in all its storage and processing systems.
> 2. *Real-time data processing*—Computing derived data streams.
> 3. *Distributed system design*—How practical systems can by simplified with a log-centric design.
>
> These uses all resolve around the idea of a log as a stand-alone service.
>
> In each case, the usefulness of the log comes from simple function that the log provides: producing a persistent, re-playable record of history. Surprisingly, at the core of these problems is the ability to have many machines playback history at their own rate in a deterministic manner.
>
> ***Part Two: Data Integration***
>
> Data Integration的定义
>
> > Data integration is making all the data an organization has available in all its services and systems.
>
> This phrase "data integration" isn't all that common, but I don't know a better one. The more recognizable term [ETL](http://en.wikipedia.org/wiki/Extract,_transform,_load) usually covers only a limited part of data integration—populating a relational data warehouse. But much of what I am describing can be thought of as ETL generalized to cover real-time systems and processing flows
>
> ![](https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/datapipeline_complex.png)
>
> 现在的通用方案
>
> ![](https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/datapipeline_simple.png)
>
> 
>
> ***Part Four: ***
>
> ### The place of the log in system architecture
>
> A system that assumes an external log is present allows the individual systems to relinquish a lot of their own complexity and rely on the shared log. Here are the things I think a log can do:
>
> - Handle data consistency (whether eventual or immediate) by sequencing concurrent updates to nodes
>
> - Provide data replication between nodes
>
> - Provide "commit" semantics to the writer (i.e. acknowledging only when your write guaranteed not to be lost)
>
> - Provide the external data subscription feed from the system
>
> - Provide the capability to restore failed replicas that lost their data or bootstrap new replicas
>
> - Handle rebalancing of data between nodes.
>
>   ![](https://content.linkedin.com/content/dam/engineering/en-us/blog/migrated/full-stack.png)
>
>   
>
> .





#### Reference

1. [The Log: What every software engineer should know about real-time data's unifying abstraction](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)

