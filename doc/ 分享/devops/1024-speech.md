#### 演讲内容

hello，各位小伙伴好，我是来自csig医疗线的Michael，我们这次分享的主题是： 腾讯云医，基于腾讯云的研效精益实践

#### 大纲介绍

本次的分享会分为6个部分，第一部分和第二部分是介绍一下业务背景，以及我们为什么要做研效。第3-5部分是我们做研效的三个阶段。最后一个部分是我们做研效过程中的一些心得体会，以及对未来的展望

#### 背景

腾讯云医是完全基于腾讯云打造的一款医疗行业产品，前端的入口是微信小程序，提供了基于互联网的问诊，处方，开药等完整流程，同时服务于医患管理以及和整合相关生态合作伙伴的一款产品

#### 为什么做研效

***跟物理学发展有点类似的是，从经典物理，到广义，狭义相对论，到最后的量子力学，物理学的进展越来越难***

***一句话概括，就是低垂的果实已经没有了***

~~互联网经历PC，移动两个大时代的用户增长后，以及从社交，到信息流，到短视频后，当下的移动互联网，所有产研团队面临的共同问题是，还有什么点可以让用户兴奋，或者什么方案可以解决用户真实的难题~~大家采用的策略都是在某个细分的领域，不断的尝试突破。云医这款产品也是尝试在医疗行业深耕，从多个途径寻找方法解决医患现实中的各个痛点，从去年年中立项，我们先后探索过多个方向，也在业务的各个流程上涉及了多个业务合作伙伴，这个过程中就要求研发团队要灵活，快速，能跟上业务的节奏； 那么我们是否可以通过增加人手来提升交付效率呢？软件工程领域不断验证的brooks法则表明，研发人力的增加，会使交付周期在一定程度下降后，又回到逐步增加的通道上。本质上的原因是，任务本身也有最小不可分割的单元性，而且即使可以切割时，任务的分割会引发额外的工作量，熟悉现有系统，更多的相互沟通；

那么怎么解决我们面临的这些矛盾呢？

软件行业整体发展史上来看，从瀑布流开发模式，演进到敏捷开发，到目前主流的DevOps，大部分数据都显示了这样做可以提升研发的整体效率。我们项目立项封闭阶段是典型的瀑布流，原型完成后，是典型的敏捷开发直到上线；随着今年4月正式发布后，更快，更灵活多变的业务方向，研发效率已经逐渐成为了瓶颈。自然地我们也逐步需要过渡到DevOps流程。这一点和业界大多研发团队的演进历史非常类似。

下面我们就介绍腾讯云医DevOps演进历史，采用的核心思路是小步快跑，尽快尝试尽快调整。整体上，可以分为三个阶段

#### 1.0

云医腾讯云医的整体后台是基于云原生构建的，devops的实践我们也期望能构建一套基于云原生的devops解决方案。我们去年底总结了一下，我们面临的主要是两个核心问题

1. 怎么提升研发效率，从而满足业务迭代的诉求
2. 快速迭代的业务难免线上引入不符合预期的情况，有些是产品的问题，有些是程序的，那么怎么快速定位问题然后解决，也是我们急迫需要解决的

我们按照devops理念，把整个研发流程划分了五个领域，覆盖了开发，构建，测试，部署，运营，然后分析了没个领域下的需要亟待解决的问题，然后按照把最痛的问题优先解决的思路，而在制定方案落地时，则采用先做可用性，然后再做易用性的方针，用这两个指导思想来逐步解决我们的问题。

整个devops落地的过程中，我们则是采用开源协同，绝不造轮子的的方式推进

##### 开发域效能的提升

第一个阶段，我们主要是面临的三个问题，

第一个是开发模式不统一，有人是分支开发，有人是主干开发，互相覆盖时有发生，我们全部统一到了分支开发，主干测试的流程上来

第二个是分支习惯不统一，需求和分支无法对应，代码无法追溯。我们构建了基于tapd自动创建分支，代码提交清晰可见

第三个是同一个模块上的需求容易互相影响，引入feature toggle，降低相互影响

同时对于开发需求过程中，针对开发需要协同产品，项目经理，测试等情况，我们采用了chatops的方式自动拉迭代群，评审状态自动更新，转测，测试完成，发布等都会在群里自动更新，使需求迭代的整体流程自动化，提升了沟通效率

##### 构建/部署领域

我们基于coding研效平台，采用了五条流水线，自动化的覆盖了CI/CD过程，把人工操作的环节都变成了自动划一键操作， 开发人员操作精简到了6个步骤

##### 测试领域

主要是协同CSIG的质量部，做了自动化拨测门禁，嵌入到测试，予发布流水线，线上不再发生发生历史问题

开发并行的问题解决后，我们需要解决的是测试并行的问题。我们采用了基础设施即代码的思路，通过coding的cle，实现了测试环境的快速搭建，就做到了多特性环境的快速生成，可以让测试环境同时并行多个版本

##### 运营领域

运营领域，我们通过芸产品cms构建了基本的接口监控和告警，提升了我们线上定位问题的能力

##### 总结

总结来看，我们把开发模式混乱，手工构建等最痛的问题做了一遍梳理解决，做到了基本的并行测试和质量保证。但我们仍有很多问题遗留，而这些问题随着微服务数量的增加，也变得越来越重要

#### 2.0

在有了第一个阶段的总结后，我们得到了一些经验，

第一个就是XAC确实是一个有效的解决思路，能快速的自动化流程，比如测试环境的一键生成；

第二个是，服务数量越来越多，而测试人员不可能和服务数量有一个恰当比例的增加，需要我们采用测试左移的思路来提升研发质量

第三个是，微服务下，问题的定位，需要更加工业化的手段，也就是可观测体系的建立

##### 开发领域

***降低沟通成本，是研效提升的一个有效手段***

开发域的问题我们总结和抽象后，变成了两类问题，

第一个，我们需要一个标准化，标准是降低沟通和理解成本最有效的方式，比如库的统一，协议的统一，代码组织方式的统一。做到了这个，研发效率自然就会有个小幅度的提升

第二个，标准化不能靠人工执行，因为这样一定没有办法执行到位，人总会有犯错的时候，这个时候我们就需要自动化来实施标准

如表格所示，我们对新服务做了仓库，资源的统一，协议的发布也做了统一

具体来看，基本上服务都有会用到七彩石，数据库，名字服务和负载均衡，日志，监控，ci&cd等等，那么我们就把这些通过工具自动生成，如右图所示，每个同学生成的服务都是这样的组织方式，我们在做跨服务修改的时候，沟通成本就降下来了。同时我们，我们把工具和Coding的流水线做了打通，这样测试和发布也方式也都是一致的，进步降低研发彼此间的理解成本

比如这个效果图，整个代码仓库和相关服务的流水线是通过coding的编排能力来实现的

proto的标准化也是类似的，核心就是降低研发间的沟通和理解成本

我们做了proto构建的统一

我们也做了proto发布的自动化流水线，这里也是我们讨论很多的一个点，proto的提交和发布，应该先于业务代码，同时应该用XAC的方式，定义好依赖关系。而且通过协议前置，降低了前后或者后后联调的沟通成本，很多问题不会到联调才发现彼此理解不一致

##### 测试域优化

1.0 中我们实现了测试环境并行的能力，但是随着服务的增多，我们对资源的消耗会比较浪费，我们对此也做了基于服务网格的增量环境优化，在保证并行测试的同时，节约了成本。

同时这个部分也是通过工蜂的webhook实现了自动化，这里是效果图

测试域的另外一个问题是，我们是冰激凌模式，也就是基本上一开始完全靠测试同学手工测试保证，当人工跟不上膨胀的功能时，bug就会不断增多。另外，整个开发过程中也是开发阶段引入bug最多，且开发阶段解决成本最低，所以业界都在过渡到金字塔的开发模式。也就是尽可能在开发阶段，保证研发质量。

我们把单测门槛自动化嵌入整个流水线，来保证提及的代码一定是有一定覆盖率的。但是我们也发现，覆盖率是一把双刃剑，不能太高也不能太低，跟研发团队自身也有关系，不能一概而论。是研发满意度和质量之间的一个trade off

另外我们也通过文化建设做了一些激励，来鼓励大家能接受这个要求，慢慢去体会这个过程中带来的好处

整体上，我们的单元测试覆盖数是一直在增加，重要的是单测也确实发现了一些代码可能有潜在风险

另外一个测试左移的方法是CR，实践来看，对于公共库的效果是最为明显，

第一，公共库的问题归零了

第二，公共库的推广更加容易了

测试左移的第三个优化是，自动化回归测试；当测试人力跟不上接口和功能的膨胀后，我们一直在思考的就是，集成测试和系统测试怎么提升？一个想法就是，现网用户的操作能否作为我们的测试用例，

整体思路就是，线上的服务不断的录制请求和对应的返回，然后不断回放到我们将要发出去的服务上，回放的用例如果都没有问题，至少新版本对历史功能的正确性就有比较大的置信度。

这里是我们实现的一个服务的录制效果，测试同学人工用例的覆盖度是26，线上录制2小时大约已经了50

##### 运营域

其实，前面的很多领域，在10年前的CI/CD概念里也都可以覆盖，但devops里面最重要的是引入了一个概念，就是ci/cd后，加入了co

微服务体系下，可观测是co的实现的基石，我们也是围绕着可观测的三大支柱metrics，loggng，tracing分别做了优化

metrics部分，我们讨论最多的，和实现比较成熟的是构建了指标的分类体系，并且完全基于腾讯云来实现。构建了业务指标，服务指标，系统指标。这个是基于云监控实现的架构图，

过程中比较有挑战的是，我们给出了一套grpc-go在云监控上的最佳实践，也在参与公司open telemetry 的oteam

这里是效果图，分别是进程，中间件，服务和自定义指标

可观测第二大支柱是tracing，我们也是构建了基于腾讯云apm的tracing解决方案，这里是整体的结构图

tracing上线后也确实提升了我们的服务质量

日志部分，我们也是升级到了腾讯云原生的cls上，同时我们也基于error日志来丰富我们的告警体系

整体上，通过构建云原生的三大可观测体系，研发质量和研发同学的幸福感得到了提升，同时在这个过程中，我们也协同了公司的多个组织

co的实践中，我们实际的感受是，可观测是co的基石，但是co不应该只有可观测；最大的一个特点是，服务都是正常的，但是某一项业务指标可能逐渐不符合预期，这里就需要我们尝试在co体系中增加业务运营数据

这里我们采用了大数据体系的解决方案，通过数据采集整理，数据加工，数据检索和分析三个阶段来构建我们业务运营关心的能力，并把这些融入到我们co体系中。这个部分我们也是完全基于云原生的大数据处理和分析体系，来验证我们的功能迭代上线后，用户的行为数据是否符合我们的预期，判断是否有异常。这个部分，我们还在持续的迭代过程中

这里是一些关键的运营指标展示，比如有注册漏斗和用户行为路径

##### 总结

第二个阶段后，我们基本上完成了我们一开始设立的目标，所有的解决方案看上去也基本上满足了可用性，剩下的就是要想办法提升易用性。

这里我们发现的核心点就是，谷仓效应，各个模块的解决方案是分散在各处的，通常需要登陆多个平台才能完成操作，那么有么有办法来拉通，做一次全局优化呢。



#### 3.0

调研后，我们发现coding研效平台可以有效的解决我们的痛点。coding是把研发流程做了标准化的定义，然后给出了一站式的解决方案。

具体来看，以应用视角，就是一个微服务，可以通过配置，中间间，协议，网关等模块和右侧的云基础设施全部打通，这样研发小伙伴基本上就在一个平台上完成了ci，cd，co的全部流程。

这个过程中，我们也是和coding研效平台协同，在实践中一起打磨产品

这个是我们一个服务的具体效果图



#### 总结思考

* 研发本质上也是一个产品

  ​      我们在实践过程中发现，研发团队一直做的是两个产品： 第一是我们公司交给我们的一款产品或者工具；而另外一款产品，我们每天自己在做的，就是研发团队本身，而其中最重要的一部分就是研发流程的优化。既然是一款产品，那么我们就可以不断的迭代优化，提升使用这个产品的用户--也就是我们研发团队自身的满意度。所以每次流程的优化，都要有一个核心的出发点，就是每次的提升是不是解决了某个问题，是不是真的提升了我们团队研发同学的幸福感

     * 小步快跑： 我们在产品迭代或者架构优化中，经常采用的手段。用在研发流程优化上也比较合适，好的改进一开始也许大家也是不适应的，步子不宜迈的太大。		
     * 三现主义：大意是指流程优化好不好用，不是做这个的人说了算。做流程优化的同学，、要亲自去“现场”，亲眼见到“现物”， 探索真正的“现实”再做决策。
     * 定期复盘： 这个比较好理解了，就是，所有做的流程定期拿出来讨论。好的地方，做推广的同时，也想想能不能再做优化，不好的地方指出来，大家聊聊甚至吵吵也都可以，试图回到正确的路上；			

   * 业务是由流程和组织方式共同决定的

        * 实践中发现，研发流程不是唯一的因素，另外一个核心因素是团队的组织方式，比如说，一开始我们是模块负责制，也就是一组模块是几个人的小团队负责，但是在我们在流水线初步建立后，迭代效率提升了，很快就遇到的一个瓶颈是，热点模块问题，类似于hot key，很多需求也会交叉设计到几组模块，导致这几组模块的负责同学一直是效率瓶颈，而这个时候，研发效能的优化已经没有明显效果 ，只有工作组织方式的变革，才能进一步提升工作效率
        * 但是，无论是组织方式优化，还是流程优化，我们都需要谨记的一点是，研发小伙伴的满意度提升才是唯一的北极星指标	

#### 展望











##### 龙哥讲稿


这部分由我来给大家分享下运营域相关的工作，也就是可观测内容



我们云医业务是从去年6月份开始启动的，随着业务的快速迭代，微服务架构的优势没有体现出来，反而因为微服务架构的使用，导致服务之间调用链路比较长、定位问题难。主要体现在以下三个方面：第一个是日志分散、查询效率低；第二个是指标太少、出现告警时无从下手；第三个就是服务之间缺少调用链



针对微服务的这些共性问题，业界的解决方案是可观测性的建设。可观测的理念能够让开发做到对系统一切尽在掌握。所以接下来内容也从可观测的三个支柱入手，看它是如何帮助我们云医业务解决线上定位问题以及解决问题慢的情况。



首先我们来看下监控指标的建设，针对监控指标方案，我们的目标一个是简单易接入，符合业界开源的标准；一个是能够支持更加丰富的指标上报，比如服务指标/系统指标/还有些业务自定义指标；并且最好是云原生的方案。



我们通过对比、调研了几种监控方案之后，选择了云监控的监控系统。这是系统的架构图：我们采用开源的prometheus exporter以及push gateway来采集数据，并且使用sidecar的方式来部署tccm agent上报数据，最后通过grafana配置指标仪表盘以及告警



在监控指标的接入过程中，碰到的问题是-没有grpc相关的实践指引，所以对于grpc应该关注哪些指标维度、以及grpc的指标面板应该长什么样子，我们做了一些思考和实践。这里主要借鉴了公司内otel oteam中trpc-go的指标实现，并且基于监控RED(rates/error/duration)原则，在每次grpc请求会记录3个系统指标(包含client端和server端)，最终通过grpc的Interceptors来暴露系统指标。这套方案目前已经成为云监控grpc-go的最佳实践，我们也在和bg的研效同学一起协同共建gRPC-go框架的公共库。并且也在推动成为公司内otel oteam的grpc-go标准



这是我们的进展情况，现在所有服务都已经接入了metrics，右边是具体的监控指标，包含了系统服务指标、自定义指标以及大盘数据



指标监控OK了之后，接下来分享下我们Logging是如何做的。针对日志我们提出了三点目标：第一个是提供结构化的日志库；第二个是最好是云原生的产品；第三个点是能够跟traceid集成，方便服务之间的串联分析。通过对比调研之后，我们选择了腾讯云cls。这是日志上报的架构：也是通过sidecar的方式，部署loglistener agent上报日志数据，使用cls控制台来进行检索、分析



这是我们日志检索的效果图，它可以非常方便的按索引字段来检索日志，目前已经成为我们团队内排查问题的主要工具；并且针对日志可以做一些告警以及看板类的仪表盘



我们的监控以及日志基本都OK了，接下来分享下我们服务调用链治理的工作。从图中可以看到，我们仅通过日志和监控提供的数据，不可能一目了然地看到一个请求的生命周期是什么样的。在可观测中，通过tracing系统可以提供用户一次请求完整的上下文信息。我们对公司内外的tracing系统做了充分调研之后，选择了云监控APM，并且我们也采用了otel协议标准来采集和上报数据



这是我们接入tracing的架构图，我们使用了grpc 拦截器的方式采集数据，使用jaeger exporter把数据暴露给otel collector，最终上报给云监控APM。这里Otel collector也是通过sidecar的方式进行部署



这是我们接入tracing后的效果，它可以帮助我们梳理服务之间的调用链路以及快速的定位问题



刚才提到我们可观测的三个指标都是通过sidecar的方式来单独部署的，但是在服务实例较多的情况下，这三个agent是比较耗费资源，并且不好维护的。最终我们和coding的同事一起协同，将3个agent合成了一个，方便以后的标准化以及也节省资源



到这里我们基本上解决了我们云医服务的可观测问题，中间这张图是我们整个可观测数据上报的架构图。最终我们通过使用云上产品作为基础组件，配合我们的服务治理形成了最佳实践，帮助业务提升发现、定位问题的效率。并且我们也取得了一定的成绩，我们接入的云监控grpc-go方案，已经成为云监控认可的最佳实践；并且方案已经在部门内推广使用；也正在参与coding相关的建设工作



最后一部分是总结和展望



通过devops的建设，我们取得了一定的成果，例如通过服务脚手架新增服务-由原来的天级到分钟级；测试环境也是人手一套；发现以及定位问题的效率也从原来的半小时优化到分钟级



这里我们把前面提到的devops各个域的工作都做了优化，但是当时并没有一个统一的管理平台，能够把各个域的工作串联起来、做到平滑的过渡。也就是缺少统一的管理平台



跟coding的同事交流之后发现，coding应用管理正在做这方面的工作。coding应用管理将多个域串联在一起、整合成一个管理平台。所以我们的目标是把coding应用管理作为基座，协同共建，进行全局优化，进一步提高云医的研发效率



这是我们和coding应用管理平台，在协同-开发过程中提出的需求情况，这其实也进一步完善了应用管理的能力



我们云医也在逐步迁移coding应用管理平台，当前已经接入了21个服务



我们的分享结束，谢谢大家！
